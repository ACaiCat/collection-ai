# README

##### 考核任务完成情况

- 完成了numpy实现softmax函数和mnist手写数字辨识任务，也做了用numpy实现手写数字辨识的考核，但确实感觉有难度暂时未能完成，也提交了代码（但这过程使得我对卷积神经网络有了更为深刻的理解）
- mnist手写数字辨识任务使用了三层的神经网络，效果还不错，可以在未见过的测试集上达到98.56%的正确率
- numpy实现手写数字辨识那题完成了conv，max_pooling，relu，backward_propagation等函数的实现，但是不知道如何把这些方法串在一起用来训练
- 编译器我是使用安装了github copilot的pycharm来编写jupyter notebook，所有使用了一定的ai工具辅助（尤其是numpy实现手写数字那题，问了gpt许多问题来使得我可以理解代码）

##### 学习笔记说明

- 我参加了java和ai方向的两项考核，原先是想把java作为主语言，python作为辅助语言进行学习，但在这一段时期的深度学习的学习中，我感觉学习人工智能是非常让人兴奋的（再加上java对数据库进行增删改查操作确实枯燥），我想我应该做出一定的改变，以后会把python和ai学习作为主力方向
- 深度学习以及Pytorch的课程不如java那么多，要找到适合自己的课程更是困难，这段时间我也是试听了许多的课，包括各种号称全站第一课，最后决定台大李宏毅的课程最为适合我，也最为能让我理解人工智能的底层原理。在代码实现方面，我听了up主蓝斯诺特的pytorch2快速入门并跟着敲了一遍代码（代码也进行了上传），此外觉得吴恩达以及沐神的课也不错，光听快速入门肯定不足，后面应该会多听沐神的课来更深入学习代码实现
- 深度学习的课主要是在一些水课以及一些琐碎时间上听的，因此没有特别去记笔记，就截了许多的图，感觉把截图全布拼起来作为笔记我也不可能去看，所以我通过了我的理解进行了复述
- 目前线性代数和微积分知识的缺漏对我进一步理解深度学习造成了印象（最近在听逻辑回归的时候明显感受到缺陷），后面可能会先偏向花一定时间完成线代和高数的学习

##### 学习笔记

所谓机器学习，就是用机器去寻找一个函数，而机器学习的过程就是尝试去拟合这一个函数

在机器学习过程主要分作三个步骤，第一步确定一个函数具有不确定的参数（Function with Unknown Parameters），第二步确定一个loss函数以判断模型的好坏（Define loss from Training Data），第三步对模型进行优化（Optimization）

###### 第一步 寻找函数

根据数据集寻找可能的映射关系，比如预测天气就是要寻找当天天气与前一天各项天气指标的关系，要进行图像识别就是要寻找画面的图像与每个像素的关系

机器学习可以分做以下几类，不同类所需的数据集类型不同：

1. **监督学习**：给每个数据都打上标签让机器学习数据和标签的映射关系（这样的数据集一般很贵）
2. **无监督学习**：单纯把一堆数据丢给机器，让机器自己去理解数据之间的关联性，主要应该会用在生成式ai上吧（我个觉得，就像给你看了大量大师的画你也可以知道怎么画一张好画）（chatGPT就是先进行了大量的无监督学习再通过监督学习和强化学习的微调实现的）
3. **强化学习**：对机器产生结果的好坏进行评估，通过好坏进行参数的调整（评估不一定是自己评估，可以让ai和自己进行大量的博弈比如自己和自己打无数把dot2，根据输赢进行评估）（这样做就不需要数据集）

在确立好关系后会对所需的参数进行随机的初始化

###### 第二步 定义loss

及算出预测结果和真实结果之间的差值，给予模型反馈，使得其有方向调整参数

常见的loss函数有MSELoss(平方差的和)，CrossEntropy(交叉熵)

###### 第三步 优化模型

**梯度下降算法**：算出最好模型即相当与在参数为各种可能时所构成的loss函数上找到一个最小的点，在参数非常多的情况下要穷举所有可能是不现实的，所以我们需要找到一条下山最快的路，于是我们根据山坡的坡度即斜率也就是导数，和我们内心自己估计的学习速率来决定我们从那个方向下山，从这个方向要走多少的路。

梯度下降算法可能会遇到鞍点（critical minimum)和局部最小值（local minimum）但好在这个概率是非常低的，因为一个二维曲线的最低点放到三维曲面上可能只会是一个鞍点，所以在参数如此庞大可能上万上亿维的高维空间内出现local minimum的可能性是非常小的

**反向传播**：由于对如此复杂的神经网络直接进行求导是先当困难的，所以有了反向传播（实际也就是链式法则罢了）

我觉得3B1B的解释特别好，就是当遇到一个loss反馈后每个输出结果对应的神经元都希望能够降低loss即调整他们之前的参数使得他们的值可以更趋向期望的值，于是他们给出他们的导数告诉前面的神经元调整方向。而前面的神经元也会希望做出相应的调整，于是他们告诉前面的神经元他们的导数....

**激活函数**：参数和输出结果的映射是相当复杂的，于是我们用sigmoid和relu这样像是函数的叠加去逼近



#### **卷积神经网络CNN**

主要使用在影像识别上（alphaGo也是使用CNN）

数据集必须是相同大小的图片（在应用时候要先把输入影像压缩到所需大小）

使用cross entropy计算loss
$$
H(p,q)=−∑ 
x
​
 p(x)logq(x)

$$
图像是有3维的tensor（长，宽，RGB三个颜色）

把每个像素点都拿出来排成向量作为输入

只要侦测到关键部位就可以判断因此可以不用看全部图片，而成只要看Receptive field(可以重叠)

关键部位可能会在图片的任何位置，因此有些Receptive field可以共享参数(filter)

这两步可以降低模型的弹性（不容易overfitting）（有比较大large model bias）

convolution layer有许多filter（kenal size*channel）每个filter检测一个关键pattern，通过线性回归可以获得每个filter的参数，把filter的全部值和每个receptive filed相乘获得一个新的值从而获得一个“新的图像”（feature map）（当遇到与要检测元素相似性最高时值最大），每个filter可以给一个新的channel,所以新图片channel数变大，size变小

新的图像再进行卷积意味可以覆盖跟多的像素，因此只要叠的够深就可以检测足够大的图像

**卷积**：就是把filter扫过一张图片的过程

pooling池化：把图片缩小不改变图片的样子，pooling不是一个layer，有点像sigmoid（可以减少计算量，可以不用）

flatten把最后得到的图像拉直然后丢到fully connected layer进行softmax回归

计算卷积后大小的公式:
$$
O = \frac{{I - K + 2P}}{{S}} + 1
$$

- **O**：输出尺寸（Output size）。它是根据输入尺寸、卷积核大小、填充量和步长计算出的输出特征图（feature map）的尺寸。
- **I**：输入尺寸（Input size）。这是卷积层接收到的输入特征图的尺寸。
- **K**：卷积核尺寸（Kernel size）。这是卷积操作中使用的卷积核（或滤波器）的尺寸。
- **P**：填充量（Padding）。这是在输入特征图的边缘添加的零填充的数量。填充通常用于控制输出尺寸，防止尺寸过于迅速地缩小，或者为了保持特征图的空间尺寸。
- **S**：步长（Stride）。这是卷积核在输入特征图上移动的步长。较大的步长会导致更小的输出尺寸。



#### **分类classification**

loss的计算（分类错误的次数）
$$
L(f) = \sum_{n} \delta(f(x^n) \neq \hat{y}^n)
$$
如何计算：概率论->贝叶斯公式
$$
P(C_1 | \mathbf{x}) = \frac{P(\mathbf{x} | C_1)P(C_1)}{P(\mathbf{x} | C_1)P(C_1) + P(\mathbf{x} | C_2)P(C_2)}
$$
通过在从c1和c2中抽取到x的概率得到给定x来自c1或c2的概率

全概率公式
$$
P(A) = \sum_{i=1}^{n} P(A | B_i) P(B_i)
$$
高斯分布（正态分布）
$$
f_{\mu,\Sigma}(x) = \frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}} \exp\left\{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right\}
$$


最大似然估计：找一个高斯分布找到所有测试点的概率最大，而通过数学可以知道：

当
$$
\mu^* = \frac{1}{79} \sum_{n=1}^{79} x^n
$$

$$
\Sigma^* = \frac{1}{79} \sum_{n=1}^{79} (x^n - \mu^*)(x^n - \mu^*)^T
$$

（第二个参数可以共用以减少参数）

时这个高斯分布得到的概率最大

这时这个公式就可以算了就可以得到x来自c1的概率
$$
P(C_1 | \mathbf{x}) = \frac{P(\mathbf{x} | C_1)P(C_1)}{P(\mathbf{x} | C_1)P(C_1) + P(\mathbf{x} | C_2)P(C_2)}
$$

